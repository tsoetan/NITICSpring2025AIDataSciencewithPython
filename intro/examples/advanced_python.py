# -*- coding: utf-8 -*-
"""AIPy 1C - Python Fundamentals.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aZJ4bACBMgM9jc5-uZBcxXwNN1KSulb_
"""



"""## List comprehensions"""

# Traditional loop
squares = []
for x in range(10):
    squares.append(x**2)
print(f'Loop: {squares}')

# List comprehension
squares = [x**2 for x in range(10)]
print(f'Comprehension: {squares}')

"""### Example: Preprocessing Text Data"""

# Preprocessing text data
words = ["Hello", "World", "AI", "Python"]
word_lengths = [len(word) for word in words]
print(word_lengths)

# Feature extraction
features = [
    [1 if char in word.lower() else 0 for char in 'aeiou']
    for word in words
]
print(features)

# Data normalization
data = [10, 25, 5, 15, 20]
normalized = [(x - min(data)) / (max(data) - min(data))
              for x in data]
print(normalized)

"""## Lambda Functions"""

# Traditional function
def square(x):
    return x**2

# Lambda function
square = lambda x: x**2

# Map example - applying function to all elements
numbers = [1, -2, 3, -4, 5]
squared = list(map(lambda x: x**2, numbers))

# Filter example - selecting elements
positive = list(filter(lambda x: x > 0, numbers))

print (squared)
print (positive)

"""## Examples from AI"""

quote = "Whatever this is that I am, it is flesh and a little spirit and an intelligence."
# Feature scaling
scale = lambda x: (x - x.mean()) / x.std()

# Custom activation function
relu = lambda x: max(0, x)

# Text preprocessing
clean_text = lambda text: text.lower().strip()

clean_text
clean_text(quote)

"""## Decorators"""

def my_decorator(func):
    def wrapper():
        print("Something is happening before the function is called.")
        func()
        print("Something is happening after the function is called.")
    return wrapper

@my_decorator
def say_hello():
    print("Hello!")

say_hello()

"""### Decorator with arguments"""

def timer(func):
    def wrapper(*args, **kwargs):
        import time
        start = time.time()
        result = func(*args, **kwargs)
        print(f"Function took {time.time() - start:.2f} seconds")
        return result
    return wrapper

@timer
def train_model(data):
    # Simulate some work
    sum = 0
    for i in range(1000000):
        sum += i
    return sum

data = None  # dummy data
result = train_model(data)
print(f"Result: {result}")

def batch_generator(data, batch_size=32):
    """Generate batches of data for training"""
    for i in range(0, len(data), batch_size):
        yield data[i:i + batch_size]

# Test data
training_data = list(range(10))  # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
for batch in batch_generator(training_data, batch_size=3):
    print(f"Processing batch: {batch}")